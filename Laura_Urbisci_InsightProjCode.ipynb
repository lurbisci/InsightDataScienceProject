{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laura_Urbisci_InsightProjCode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lurbisci/InsightDataScienceProject/blob/master/Laura_Urbisci_InsightProjCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wlY2PM2SPL-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Insight Data Science Project\n",
        "## The Ron Burgundy, the scotch whisky recommender\n",
        "\n",
        "__Date:__ January 2019   \n",
        "__Author:__ Laura Urbisci\n",
        "\n",
        "___\n",
        "\n",
        "## Project overview:\n",
        "The Insight program takes data scientists with PhDs in various quantitative fields and helps them further develop their skills by tackling a real world data science project in just 3 weeks. \n",
        "These projects demonstrate Fellows’ familiarity with industry-standard tools as well as their ability to build a project from scratch in a short amount of time. Projects come in two types: individual projects and consulting projects. For individual projects we develop our own idea, and for consulting projects, we work with a startup company to solve their data problems. I did an individual project which I called the Ron Burgundy, the scotch whisky recommender. My app takes Reddit data to recommend scotch so that whisky lovers can find new products to try. I used collaborative filtering for my model and deployed my app on AWS (the ronburgundy.com).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "lVthJF55T_dt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data acquisition\n",
        "\n",
        "This section of the notebook contains the packages needed to run all of the code in this notebook in addition to the code used for data extraction.  \n",
        "\n",
        "<br>\n",
        "\n",
        "We obtained data from the following sources:\n",
        "1. The majority of the data can be found [here](https://docs.google.com/spreadsheets/d/1X1HTxkI6SqsdpNSkSSivMzpxNT-oeTbjFFDdEkXD30o/edit#gid=695409533). The link contains mutiple structured tables pre-gathered from Reddit on Reddit Username, Whisky, and Whisky Review. I used the Review Archive tab for training and testing data and the Best by User tab for the validation data set.\n",
        "2. I gathered whisky data from the [Meta-Critic Whisky Database](https://whiskyanalysis.com/index.php/interesting-correlations/how-to-read-the-database/). This data was used to supplement the Reddit data and provide descriptions on the whisky for the final product. \n",
        "\n",
        "<br>\n",
        "\n",
        "I first installed and imported all the necessary packages for the analysis."
      ]
    },
    {
      "metadata": {
        "id": "-Fo4biEGPH3P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import all of the necessary Python packages\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "from pylab import savefig\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Embedding, Reshape, Activation, Input, Dense, Flatten, Dropout, dot\n",
        "from keras.constraints import non_neg\n",
        "from IPython.display import SVG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43BPUNrCWbYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up directory for data\n",
        "import os\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Insight'\n",
        "\n",
        "os.chdir(data_dir)\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9VtsnUHWWpdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_reddit = pd.read_csv(\"Reddit Whisky Network Review Archive - Review Archive.csv\")\n",
        "whisky_reddit.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d0lDDIr7WthS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_origin = pd.read_csv('Meta-Critic Whisky Database – Selfbuilts Whisky Analysis.csv')\n",
        "whisky_origin.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "djKToRduXUsX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_val = pd.read_csv(\"Reddit Whisky Network Review Archive - Best by User.csv\")\n",
        "whisky_val.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLE4jhxpUF3d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data cleaning\n",
        "\n",
        "The Reddit data needed to be cleaned before analysis. Some of the features were not useful for the modeling approach and therefore were excluded. One of the columns (i.e., Cost) needed to be transformed into a form that is readible by Python. Trailing white spaces were removed. In addition, multiple columns have missing values. I decided to eliminate the rows with missing data. The Reddit data set also was merged with the descriptive data set.  I then used label encoding to turn the categorical variables into numeric variables.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "z6IeXPLVUIDx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_reddit.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zmf0kEvKWzmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_origin.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7IFOhPLXYDIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colsToDrop = ['Link To Reddit Review', 'Date of Review', 'Timestamp', \n",
        "'Month', 'Day', 'Time', 'am pm'] # remove some columns out \n",
        "reddit_v2 = whisky_reddit.drop(colsToDrop, axis=1)\n",
        "\n",
        "reddit_v2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RCUCXAKwYDLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colsToDrop3 = ['Super Cluster'] # remove some columns out \n",
        "descrip_v2 = whisky_origin.drop(colsToDrop3, axis=1)\n",
        "\n",
        "descrip_v2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prNA1mx8YDNr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# merge whiskey names\n",
        "whisky_df = pd.merge(descrip_v2,reddit_v2,left_on=[\"Whisky\"], right_on=[\"Whisky Name\"],how=\"inner\")\n",
        "\n",
        "whisky_df.head() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MC_Szd9KYDPw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# created a new column so i can keep the $ column\n",
        "whisky_df['Cost_num'] = whisky_df['#']\n",
        "\n",
        "# converting Cost column $ to number\n",
        "for i in range(len(whisky_df)):\n",
        "  whisky_df.Cost_num.iat[i] = len(whisky_df.Cost.iat[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1K0HdnBYyyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_df = whisky_df.rename(columns={'Meta Critic': 'Meta_Critic',\n",
        "                                     '#': 'Number_of_MCReviews',\n",
        "                                     'Whisky Name': 'Whisky_Name',\n",
        "                                     \"Reviewer's Reddit Username\": 'Reddit_Username',\n",
        "                                     'Reviewer Rating': 'Reddit_Review',\n",
        "                                     'Whisky Region or Style': 'Region_or_Style',\n",
        "                                     'Full Bottle Price Paid': 'Price_Paid'})\n",
        "\n",
        "whisky_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59GLg8rFYy1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# strip white spaces on character strings\n",
        "\n",
        "# created a new column so i can keep the $ column\n",
        "whisky_df['Region_cleaned'] = whisky_df['Country']\n",
        "\n",
        "for i in range(len(whisky_df)):\n",
        "  whisky_df.Region_cleaned.iat[i] = whisky_df.Region_or_Style.iat[i].strip()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rsPs1LLYy3e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colsToDrop4 = ['Cost', 'STDEV', 'Price_Paid', \n",
        "  'Region_or_Style', 'Whisky_Name', 'Year', 'Country'] # remove some columns out \n",
        "\n",
        "whisky_df.drop(colsToDrop4, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "whisky_df.shape \n",
        "# 4,506 rows and 10 columns - lost alot of data with inner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qReaqMusYy5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_df['Reddit_Review']= pd.to_numeric(whisky_df['Reddit_Review'], errors='coerce')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mTq3RQjaZIZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_clean=whisky_df.dropna(subset=['Reddit_Review'])\n",
        "\n",
        "whisky_clean.shape # down to 4,443 rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zw-FLhK8ZIbu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for validation data \n",
        "# keep only unnecessary rows\n",
        "whisky_val = whisky_val.loc[:,\"Reviewer's Reddit Username\":'tied2']\n",
        "\n",
        "# rename columns\n",
        "whisky_val = whisky_val.rename(columns={\"Reviewer's Reddit Username\" : 'Reddit_Username',\n",
        "                                      \"avg Reviewer Rating\" : 'Reddit_Review',\n",
        "                                      \"count Reviewer Rating\" : 'Number_of_Reviews',\n",
        "                                      \"1st highest rating\" : 'Rec_1',\n",
        "                                      \"tied2\" : 'Rec_2' })\n",
        "# remove unnecessary rows\n",
        "whisky_val = whisky_val.drop([\"max Reviewer Rating\"], axis=1)\n",
        "    \n",
        "# remove NAs\n",
        "whisky_val = whisky_val.dropna()\n",
        "whisky_val.shape # down to 116 rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ay-7cXJZZId3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# transform first then merge\n",
        "whisky_val_melt = pd.melt(whisky_val, id_vars=['Reddit_Username', 'Reddit_Review'], value_vars=['Rec_1', 'Rec_2'],\n",
        "                         var_name='Recommendation', value_name=\"Whisky\")\n",
        "\n",
        "# merge with description data\n",
        "whisky_validat = pd.merge(descrip_v2,whisky_val_melt,left_on=[\"Whisky\"],\n",
        "                          right_on=[\"Whisky\"],how=\"inner\")\n",
        "\n",
        "# rename columns\n",
        "whisky_validat = whisky_validat.rename(columns={'Meta Critic': 'Meta_Critic',\n",
        "                                     '#': 'Number_of_MCReviews'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TE7dJ4mCZIf_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# created a new column so i can keep the $ column\n",
        "whisky_validat['Cost_num'] = whisky_validat['Number_of_MCReviews']\n",
        "\n",
        "# converting Cost column $ to number\n",
        "for i in range(len(whisky_validat)):\n",
        "  whisky_validat.Cost_num.iat[i] = len(whisky_validat.Cost.iat[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hynJYx8CZ80O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colsToDrop4 = ['Cost', 'STDEV', 'Country', 'Recommendation'] # remove some columns out \n",
        "\n",
        "whisky_validat.drop(colsToDrop4, axis=1, inplace=True)\n",
        "\n",
        "whisky_validat.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWObmBGFaQto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_le = deepcopy(whisky_clean)\n",
        "whisky_le = whisky_le.drop(columns=['Rating_category',\n",
        "                                        'Rating_category_quantile'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXSlJGCSaRPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encode labels with value between 0 and n_classes-1\n",
        "le = preprocessing.LabelEncoder()\n",
        "#le.fit(X_train['Class'])\n",
        "#list(le.classes_)\n",
        "#le.transform(X_train['Class']) \n",
        "\n",
        "whisky_le.loc[:,'Whisky'] = le.fit_transform(whisky_le['Whisky'].astype(str))\n",
        "whisky_le.loc[:,'Class'] = le.fit_transform(whisky_le['Class'].astype(str))\n",
        "whisky_le.loc[:,'Cluster'] = le.fit_transform(whisky_le['Cluster'].astype(str))\n",
        "whisky_le.loc[:,'Type'] = le.fit_transform(whisky_le['Type'].astype(str))\n",
        "whisky_le.loc[:,'Reddit_Username'] = le.fit_transform(whisky_le['Reddit_Username'].astype(str))\n",
        "whisky_le.loc[:,'Region_cleaned'] = le.fit_transform(whisky_le['Region_cleaned'].astype(str))\n",
        "\n",
        "whisky_validat.loc[:,'Whisky'] = le.fit_transform(whisky_validat['Whisky'].astype(str))\n",
        "whisky_validat.loc[:,'Class'] = le.fit_transform(whisky_validat['Class'].astype(str))\n",
        "whisky_validat.loc[:,'Cluster'] = le.fit_transform(whisky_validat['Cluster'].astype(str))\n",
        "whisky_validat.loc[:,'Type'] = le.fit_transform(whisky_validat['Type'].astype(str))\n",
        "whisky_validat.loc[:,'Reddit_Username'] = le.fit_transform(whisky_validat['Reddit_Username'].astype(str))\n",
        "whisky_validat.loc[:,'Region_cleaned'] = le.fit_transform(whisky_validat['Region_cleaned'].astype(str))\n",
        "\n",
        "whisky_le.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2rLAPhiIUI2w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis\n",
        "\n",
        "I looked at the distribution of the Reddit reviews to see if the data was skewed. In addition, I explored if there was pairwise correlation between the official whisky critic's review (Meta Critic) and the Reddit whisky review."
      ]
    },
    {
      "metadata": {
        "id": "r6yJ7L0JZ82x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.set(font_scale=1.5)\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "ax = sns.distplot(whisky_le['Reddit_Review'], color='#800020')\n",
        "ax.set(xlabel='Reddit User Reviews of Whisky', ylabel='Density')\n",
        "\n",
        "figure = ax.get_figure()    \n",
        "figure.savefig('hist_reddit_reviews.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GAz_iVg3Z85M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = sns.pairplot(whisky_le, vars=['Reddit_Review','Meta_Critic'], \n",
        "                  kind='scatter', palette='#800020')\n",
        "\n",
        "ax.fig.set_size_inches(10,10)\n",
        "#figure = ax.get_figure()    \n",
        "#figure.savefig('corr_reviews.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frPtzTbTa3fH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.corrcoef(whisky_le['Reddit_Review'],whisky_le['Meta_Critic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oVnBQ4dJUM2o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model building\n",
        "\n",
        "Three of the features (i.e., Reddit username, Reddit whisky rating, and whisky) were very important in determining the final model I chose for this project. I originally tried other approaches such as decision tree analysis and k-means clustering, but given the output of my app, the metrics of the aforementioned models, and the three key features I decided to use collaborative filtering using neural nets. This is a common tool used for recommender systems. There are few ways to build this kind of model, but in this project I decided to focus on the product aka whisky (item-based collaborative filtering).\n"
      ]
    },
    {
      "metadata": {
        "id": "FqkPtKD8a-j0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(whisky_le, test_size=0.2)\n",
        "val_x = whisky_validat.drop(columns=['Reddit_Review'], axis=1)\n",
        "val_y = whisky_validat[\"Reddit_Review\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62lj_Wuva-md",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# how many diminsions can I think about that differentiates scotch - flavor, cost\n",
        "\n",
        "n_users, n_whisky = len(whisky_le.Reddit_Username.unique()), len(whisky_le.Whisky.unique())\n",
        "n_latent_factors = 8 # why 8 - 3 main regions, 5 different cost ranges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6OQ4FD7a-o_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_input = Input(shape=[1],name='Item')\n",
        "whisky_embedding = Embedding(n_whisky, n_latent_factors, name='NonNegWhisky-Embedding', embeddings_constraint=non_neg())(whisky_input)\n",
        "whisky_vec = Flatten(name='FlattenMovies')(whisky_embedding)\n",
        "\n",
        "user_input = Input(shape=[1],name='User')\n",
        "user_vec = Flatten(name='FlattenUsers')(Embedding(n_users, n_latent_factors,name='NonNegUser-Embedding',embeddings_constraint=non_neg())(user_input))\n",
        "\n",
        "prod = dot([whisky_vec, user_vec], axes=1, normalize=False) #Normalized: yes or no?\n",
        "model = Model([user_input, whisky_input], prod)\n",
        "model.compile('adam', 'mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2sNvfr9xa-rQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, \n",
        "                 rankdir='HB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45-Zu2g_cXWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 8,000 ish parameters to learn\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_U3EidjcXfb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add validation data in this step \n",
        "history_nonneg = model.fit([train.Reddit_Username, train.Whisky], \n",
        "                           train.Reddit_Review, \n",
        "                           validation_data=[[val_x.Reddit_Username,val_x.Whisky], val_y],\n",
        "                           epochs=100, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vWqlh6-NcXk_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_hat = np.round(model.predict([test.Reddit_Username, test.Whisky]),0)\n",
        "y_true = test.Reddit_Review\n",
        "mean_absolute_error(y_true, y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67RHV1i3cfuh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('whisky_cf_nonneg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lT0aq55ecfw9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_embedding_learnt = model.get_layer(name='NonNegWhisky-Embedding').get_weights()[0]\n",
        "pd.DataFrame(whisky_embedding_learnt).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4uLieHZ7c2Np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"dictionary_whisky.json\") as f:\n",
        "    whisky_dict = json.load(f)\n",
        "\n",
        "model = load_model('whisky_cf_nonneg.h5')\n",
        "\n",
        "whi = model.get_layer(\"NonNegWhisky-Embedding\")\n",
        "whisky_weights = whi.get_weights()[0]\n",
        "lens = np.linalg.norm(whisky_weights, axis=1)\n",
        "normalized = (whisky_weights.T / lens).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qun1ouhPcfzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def similarity_output(search_index):\n",
        "  \n",
        "  dists = np.dot(normalized, normalized[search_index])\n",
        "  closest = np.argsort(dists)[::-1]\n",
        "  return dists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Dqpwz_uc2QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create dictionary \n",
        "\n",
        "whisky_dict = {}\n",
        "\n",
        "for index, series in whisky_clean.iterrows():\n",
        "    print(series[0])\n",
        "    print(series[12])\n",
        "    whisky_dict[series[0]] = series[12]\n",
        "print(whisky_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXjdMt1Ac2Sl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"dictionary_whisky.json\", \"w\") as f:\n",
        "  json.dump(whisky_dict, f)\n",
        "\n",
        "whisky_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EA4RaQWOdGic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# don't want duplicate whisky with average score - try group by\n",
        "whisky_group = whisky_le.groupby(['Whisky'], as_index=False).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSlj9ZP1dGk0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_dict_reverse = {v: k for (k, v) in whisky_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ei9KyNMAdRE5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_group['Whisky_name'] = whisky_group['Whisky'].apply(lambda x: whisky_dict_reverse[x])\n",
        "whisky_group.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmRI3G-8de9d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "From whisky embeddings what whiskies are closest and furthest apart? Pick a random whisky and test the output as a way of \"validating the model\". "
      ]
    },
    {
      "metadata": {
        "id": "O2bM65rldRHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A = similarity_output(121)\n",
        "whisky_group['Dot'] = A\n",
        "whisky_group.head()\n",
        "whisky_group.sort_values(by=['Dot'], inplace=True, ascending=False)\n",
        "\n",
        "whisky_group"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Fp_Y5KcdRJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whisky_group.loc[whisky_group['Whisky'] == 121]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BUtSGhDqUPjr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "I build a neural net model that has two inputs (whisky name and reddit username) and a single output (rating). I focused on the whisky embedding layer to build my app. While this model is a good start, it is messy. A big challenge I encountered through the Insight data science project process was that I had to pivot twice in the beginning. This meant instead of 3 weeks to do the project I had a week and a half. In addition, I decided to learn a new modeling technique in a week (i.e., deep learning). Therefore, there are many ways I would build upon this and iterate in the future, I would try focusing on the Reddit users and see if I can see what Reddit user one would most closely associate with. I also would build a new model that used the descriptive portion of the data in the neural net. \n"
      ]
    },
    {
      "metadata": {
        "id": "-AxFlT-Ke_Ol",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}